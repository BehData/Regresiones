---

title: "Regresiones"
author: "Mayo & García"
date: "9/7/2022"
output: html_document

---


#### Regresion Lineal

##### 
Si bien mediante las correlaciones podemos medir la relación entre dos variables, las regresiones nos permitirán predecir una variable a partir de otra.

*Ejemplo. Podemos intentar predecir los niveles de estrés a partir del tiempo que falta para brindar una charla*

##### 
Se espera que la relación sea inversa (cuanto menos sea el tiempo hasta la charla, mayor será la ansiedad). Sin embargo está pregunta se puede volver más compleja.

*Ejemplo. Si faltan 10 minutos para que una persona de una charla, qué grado de ansiedad tendrá?* 

##### 
La esencia de las regresiones lineales recae en la posibilidad de ajustar un modelo a nuestros datos y utilizarlo para predecir los valores de la variable dependiente (VD) a partir de una o más variables independientes (VI). En la regresión el modelo que ajustamos es lineal, lo que significa que resumimos un conjunto de datos con una línea recta. Para hacer predicciones precisas, queremos ajustar un modelo que describa mejor los datos. La regresión lineal permite medir la fuerza de la asociación entre dos variables numéricas. También nos indica en qué dirección (positiva, negativa) ocurre esta asociación y su forma lineal.

##### 
Cualquier línea recta puede definirse por dos cosas: (1) la pendiente (o gradiente) de la línea (normalmente denotada por b1); y (2) el punto en el que la línea cruza el eje vertical del gráfico (conocido como la intercepción de la línea, b0). Aquí b1 es el gradiente de la línea recta ajustada a los datos y b0 es la intersección de esa línea.


#####
La formula de regresion simple es $$ Y_t = B_0 + B_1*X_t + e_t$$

Donde: 

$X_t$ es la variable independiente,
$Y_t$ es la Variable dependiente,
$B_0$ representa el valor de $Y$ cuando $X = 0$, 
$B_1$ representa el cambio de $Y$ por unidad de incremento de $X$ y $e_t$ es el error asociado.  

La Formula sencilla de la regresion es: $u_y = B_0 + B_1*X$

Donde:

$u_y$ es el promedio de $Y$, 
$B_0$ es el intercepto (valor de $u_y$ cuando $x = 0$) y
$B_1$ es la pendiente

---------------------------------------------------------------

#### Supuestos

*Linealidad*. Los valores de **y** dados por **x** toman una función lineal.

*Independencia de errores*. Los valores de un sujeto no afectan al otro, no están autocorrelacionados. Cuando se grafica no tiene que verse ningún patrón

*Si hay colinealidad no se puede ejecutar la regresión* (VIF) La colinealidad incrementa el valor de la varianza, si se tiene variables muy correlacionadas, los errores crecen y el valor va a crecer, lleva a creer que hay independencia de errores. 

*Normalidad*

*Igualdad de varianzas (homocedasticidad)*. La varianza es parecida para cada valor de **x**. Si no hay homocedasticidad no podría hacer buenas predicciones.

*Tipo de variables*. $X$ puede ser cualitativa(categórica) o cuantitativa, $y$ debe ser cuantitativa continua, si es discreta(número enteros altos), que tenga valores lejos de cero.

- Lo que se busca no es que en la recta estén todos los puntos, sino que se ajusten de la mejor manera (pasa sobre las medias condicionales). Se debe encontrar una media condicional dado los valores de x
- La media de los errores debe ser 0, se asume q los errores provienen de un mismo modelo generador de errores
- La variabilidad, puede haber errores con más variabilidad y con menos variabilidad (heterosedasticidad), se espera que la variabilidad sea homogenea. Si la varianza de errores es constante significa que la distancia de los errores es constante.
- p es el número de variables y k es el número de coeficientes de regresion, se le agrega uno más por B0
- Homogeneidad de varianza (se afecta el aspecto intervalar y la prueba de hipótesis cuando no hay homogeneidad de varianza). La variabilidad debe ser la misma. Los errores multiplicativos se refiere a que los datos no se acoplan al modelo de regresión lineal.
Los minimos cuadrados ponderados se usa al momento que no hay homogeneidad, sin embargo usualmente utilizamos minimo cuadrado ordinales.




$$
a^2 + b^2 = c^2
$$

------------------------------------------------------------------------



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r cars}
summary(cars)
```



```{r pressure, echo=FALSE}
plot(pressure)
```

